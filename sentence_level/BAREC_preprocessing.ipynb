{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRlk-hgfVAA8"
   },
   "outputs": [],
   "source": [
    "!pip -q install \"transformers==4.48.0\" camel-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_HBNf4uFWPJx"
   },
   "outputs": [],
   "source": [
    "!pip install -U huggingface_hub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI_H-lktW4Q9"
   },
   "outputs": [],
   "source": [
    "!camel_data -i disambig-bert-unfactored-msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEc66Nofo2r5"
   },
   "outputs": [],
   "source": [
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NWUh-9Zg-Oo"
   },
   "outputs": [],
   "source": [
    "BAREC_dataSet = load_dataset(\"CAMeL-Lab/BAREC-Shared-Task-2025-sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLmVPDE6fTux",
    "outputId": "10d457ba-49cf-4a48-d600-ce5e2a95222a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class'],\n",
       "        num_rows: 54845\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class'],\n",
       "        num_rows: 7310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class'],\n",
       "        num_rows: 7286\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "BAREC_dataSet"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding,\n",
    "                          logging as hf_logging)\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, r2_score,\n",
    "                             cohen_kappa_score, accuracy_score)\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "from camel_tools.utils.charmap import CharMapper\n",
    "from camel_tools.utils.transliterate import Transliterator\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize#no\n",
    "from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n",
    "from camel_tools.morphology.database import MorphologyDB\n",
    "from camel_tools.morphology.analyzer import Analyzer\n",
    "from camel_tools.utils.dediac import dediac_ar #no\n",
    "from functools import lru_cache\n"
   ],
   "metadata": {
    "id": "LDJEl8md7E_m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoThteyfd8Fm"
   },
   "outputs": [],
   "source": [
    "DB_PATH = None\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "\n",
    "def _load_disambiguator(db_path):\n",
    "    \"\"\"Load a BERT-based Arabic morphological disambiguator (CAMeL Tools, model 'msa') using the default analyzer (the CAMeL Tools built-in MSA morphology analyzer).\"\"\"\n",
    "    if db_path:\n",
    "        db = MorphologyDB(db_path, \"a\")\n",
    "        analyzer = Analyzer(db, cache_size=100_000, backoff=\"ADD_PROP\")\n",
    "        bert = BERTUnfactoredDisambiguator.pretrained(model_name=\"msa\", pretrained_cache=False, top=1)\n",
    "        bert._analyzer = analyzer\n",
    "    else:\n",
    "        bert = BERTUnfactoredDisambiguator.pretrained(model_name=\"msa\", pretrained_cache=False, top=1)\n",
    "    return bert\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"Cleans and normalizes Arabic text via a character map, then replaces alif maqṣūra (ى) with yā’ (ي) when it appears mid-word.\"\"\"\n",
    "    arclean = CharMapper.mapper_from_json(\"arclean_map.json\")\n",
    "    arclean_translit = Transliterator(arclean)\n",
    "    out = arclean_translit.transliterate(text)\n",
    "    out = re.sub(r'(?<=\\B)ى(?=\\B)', 'ي', out)\n",
    "    return out\n",
    "\n",
    "def diacritic_coverage(txt):\n",
    "    \"\"\"Proportion of Arabic diacritics (U+064B–U+0652) among the characters in the text.\"\"\"\n",
    "    chars = len(txt)\n",
    "    ARABIC_DIACRITICS = re.compile(r\"[\\u064B-\\u0652]\")\n",
    "    return 0.0 if chars == 0 else len(ARABIC_DIACRITICS.findall(txt)) / chars\n",
    "\n",
    "def word_len_stats(word_variant):\n",
    "    \"\"\"Mean and std-dev of token lengths.\"\"\"\n",
    "    toks = word_variant.split()\n",
    "    if not toks:\n",
    "        return 0.0, 0.0\n",
    "    lens = np.asarray([len(t) for t in toks], dtype=np.float32)\n",
    "    return lens.mean(), lens.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eY3bW0UYYLND"
   },
   "outputs": [],
   "source": [
    "def produce_variants(batch):\n",
    "    \"\"\"Build three string variants (Word, D3Tok, D3Lex) per sentence using CAMeL Tools and add them to the batch.\"\"\"\n",
    "    DISAMBIGUATOR = _load_disambiguator(DB_PATH)\n",
    "    sentences = batch[\"Sentence\"]\n",
    "    simple_tokenized_sentences = [simple_word_tokenize(clean(s), split_digits=True) for s in sentences]\n",
    "    word_sentences = [\" \".join(toks) for toks in simple_tokenized_sentences]\n",
    "    disambig = DISAMBIGUATOR.disambiguate_sentences(simple_tokenized_sentences)\n",
    "    d3tok_sent, d3lex_sent = [], []\n",
    "    for sent_disambig in disambig:\n",
    "        lex = []\n",
    "        d3tok = []\n",
    "        d3lex = []\n",
    "        # build per-token representations\n",
    "        for item in sent_disambig:\n",
    "            analysis = item.analyses[0][1]\n",
    "            lex_word   = dediac_ar(analysis[\"lex\"])\n",
    "            d3tok_word = dediac_ar(analysis[\"d3tok\"]).replace(\"_+\", \" +\").replace(\"+_\", \"+ \")\n",
    "            d3tok.append(d3tok_word)\n",
    "            # build D3Lex by swapping surface segment(s) with lex form\n",
    "            d3tok_segs = d3tok_word.split(\" \")\n",
    "            d3lex_word = []\n",
    "            for seg in d3tok_segs:\n",
    "                d3lex_word.append(lex_word if (\"+\" not in seg or seg == \"+\") else seg)\n",
    "            d3lex.append(\" \".join(d3lex_word))\n",
    "            lex.append(lex_word)\n",
    "        d3tok_sent.append(\" \".join(d3tok))\n",
    "        d3lex_sent.append(\" \".join(d3lex))\n",
    "\n",
    "    batch[\"Word\"]  = word_sentences\n",
    "    batch[\"D3Tok\"] = d3tok_sent\n",
    "    batch[\"D3Lex\"] = d3lex_sent\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-9UvqZvjX8K"
   },
   "outputs": [],
   "source": [
    "BAREC_dataSet_prepro = BAREC_dataSet.map(produce_variants, batched=True, batch_size=256, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BAREC_dataSet_prepro"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aH8pzW-BF8Q_",
    "outputId": "7e13f895-ba20-4d7f-cb72-cfbf6f1db3b2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class', 'Word', 'D3Tok', 'D3Lex'],\n",
       "        num_rows: 54845\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class', 'Word', 'D3Tok', 'D3Lex'],\n",
       "        num_rows: 7310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Sentence', 'Word_Count', 'Readability_Level', 'Readability_Level_19', 'Readability_Level_7', 'Readability_Level_5', 'Readability_Level_3', 'Annotator', 'Document', 'Source', 'Book', 'Author', 'Domain', 'Text_Class', 'Word', 'D3Tok', 'D3Lex'],\n",
       "        num_rows: 7286\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BAREC_dataSet_prepro[\"train\"][700]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmzI8ezfGujD",
    "outputId": "5c737065-ac25-4439-91fb-ff39adc3706c"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ID': 10100400030,\n",
       " 'Sentence': 'كان يشعر بألم شديد،',\n",
       " 'Word_Count': 5,\n",
       " 'Readability_Level': '10-ya',\n",
       " 'Readability_Level_19': 10,\n",
       " 'Readability_Level_7': 4,\n",
       " 'Readability_Level_5': 2,\n",
       " 'Readability_Level_3': 1,\n",
       " 'Annotator': 'A5',\n",
       " 'Document': 'BAREC_Majed_0413_1987_012.txt',\n",
       " 'Source': 'Majed',\n",
       " 'Book': 'Edition: 413',\n",
       " 'Author': '#',\n",
       " 'Domain': 'Arts & Humanities',\n",
       " 'Text_Class': 'Foundational',\n",
       " 'Word': 'كان يشعر بألم شديد ,',\n",
       " 'D3Tok': 'كان يشعر ب+ ألم شديد ,',\n",
       " 'D3Lex': 'كان شعر ب+ ألم شديد ,'}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def build_split(ds, split_name: str):\n",
    "    \"\"\"Build a fused [SEP]-delimited sequence per example.\n",
    "    Concatenates:\n",
    "      (i) corpus metadata with protected tags ([WC],[ANN],[DOC],[BOOK],[AUTH],[DOM],[TC]),\n",
    "      (ii) surface indicators [DC],[WLA],[WLS],\n",
    "      (iii) Sentence and Word, and\n",
    "      (iv) D3Tok and D3Lex.\n",
    "    \"\"\"\n",
    "    rows, labels = [], []\n",
    "    for ex in ds[split_name]:\n",
    "        dc   = diacritic_coverage(ex[\"Sentence\"])\n",
    "        wla, wls = word_len_stats(ex[\"Word\"])\n",
    "\n",
    "        field_tokens = (\n",
    "            f\"[WC]{ex['Word_Count']} \"\n",
    "            f\"[ANN]{ex['Annotator']} \"\n",
    "            f\"[DOC]{ex['Document']} \"\n",
    "            f\"[BOOK]{ex['Book']} \"\n",
    "            f\"[AUTH]{ex['Author']} \"\n",
    "            f\"[DOM]{ex['Domain']} \"\n",
    "            f\"[TC]{ex['Text_Class']} \"\n",
    "            f\"[DC]{dc:.3f} \"\n",
    "            f\"[WLA]{wla:.3f} \"\n",
    "            f\"[WLS]{wls:.3f}\"\n",
    "        )\n",
    "\n",
    "        seq_variants = \" [SEP] \".join(\n",
    "            [ex[\"Sentence\"], ex[\"Word\"], ex[\"D3Tok\"], ex[\"D3Lex\"]]\n",
    "        )\n",
    "        rows.append(f\"{field_tokens} [SEP] {seq_variants}\")\n",
    "        labels.append(float(ex[\"Readability_Level_19\"]))\n",
    "    return {\"text\": rows, \"labels\": labels}\n"
   ],
   "metadata": {
    "id": "Y2QCMqe7Hzl-"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BAREC_dataSet_prepro_ = DatasetDict({\n",
    "    split: Dataset.from_dict(build_split(BAREC_dataSet_prepro, split))\n",
    "    for split in [\"train\", \"validation\", \"test\"]\n",
    "})"
   ],
   "metadata": {
    "id": "6B6MzY4a6KUT"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BAREC_dataSet_prepro_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dSU_Ws9LxOO",
    "outputId": "a678fa3b-96a0-487c-e731-065e1326a2f8"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 54845\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 7310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 7286\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BAREC_dataSet_prepro_[\"train\"][700]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6roebiQDB_3k",
    "outputId": "75aaa3f8-0aee-4478-9024-b6af0fc77bdc"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'text': '[WC]5 [ANN]A5 [DOC]BAREC_Majed_0413_1987_012.txt [BOOK]Edition: 413 [AUTH]# [DOM]Arts & Humanities [TC]Foundational [DC]0.000 [WLA]3.200 [WLS]1.166 [SEP] كان يشعر بألم شديد، [SEP] كان يشعر بألم شديد , [SEP] كان يشعر ب+ ألم شديد , [SEP] كان شعر ب+ ألم شديد ,',\n",
       " 'labels': 10.0}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}